{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['39' 'State-gov' '77516' ... '40' 'United-States' '<=50K']\n",
      " ['50' 'Self-emp-not-inc' '83311' ... '13' 'United-States' '<=50K']\n",
      " ['38' 'Private' '215646' ... '40' 'United-States' '<=50K']\n",
      " ...\n",
      " ['58' 'Private' '151910' ... '40' 'United-States' '<=50K']\n",
      " ['22' 'Private' '201490' ... '20' 'United-States' '<=50K']\n",
      " ['52' 'Self-emp-inc' '287927' ... '40' 'United-States' '>50K']]\n",
      "(30162, 15)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "['39' 'State-gov' '77516' 'Bachelors' '13' 'Never-married' 'Adm-clerical'\n",
      " 'Not-in-family' 'White' 'Male' '2174' '0' '40' 'United-States' '<=50K']\n",
      "item is  39\n",
      "['39' '50' '38' ... '58' '22' '52']\n",
      "item is  77516\n",
      "['77516' '83311' '215646' ... '151910' '201490' '287927']\n",
      "item is  13\n",
      "['13' '13' '9' ... '9' '9' '9']\n",
      "item is  2174\n",
      "['2174' '0' '0' ... '0' '0' '15024']\n",
      "item is  0\n",
      "['0' '0' '0' ... '0' '0' '0']\n",
      "item is  40\n",
      "['40' '13' '40' ... '40' '20' '40']\n",
      "[[    39      5  77516 ...      0     40     38]\n",
      " [    50      4  83311 ...      0     13     38]\n",
      " [    38      2 215646 ...      0     40     38]\n",
      " ...\n",
      " [    58      2 151910 ...      0     40     38]\n",
      " [    22      2 201490 ...      0     20     38]\n",
      " [    52      3 287927 ...      0     40     38]]\n",
      "[0 0 0 ... 0 0 1]\n",
      "F1 score: 70.82%\n",
      "input data \n",
      "Private\n",
      "LabelEncoder()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "bad input shape ()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7d000f18f78e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0minput_data_encoded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \"\"\"\n\u001b[0;32m    127\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'classes_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bad input shape {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: bad input shape ()"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# Input file containing data\n",
    "input_file = 'income_data.txt'\n",
    "\n",
    "# Reaxd the data\n",
    "X = []\n",
    "y = []\n",
    "count_class1 = 0\n",
    "count_class2 = 0\n",
    "max_datapoints = 25000\n",
    "\n",
    "with open(input_file, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        if count_class1 >= max_datapoints and count_class2 >= max_datapoints:\n",
    "            break\n",
    "\n",
    "        if '?' in line:\n",
    "            continue\n",
    "\n",
    "        data = line[:-1].split(', ')\n",
    "\n",
    "        if data[-1] == '<=50K' and count_class1 < max_datapoints:\n",
    "            X.append(data)\n",
    "            count_class1 += 1\n",
    "\n",
    "        if data[-1] == '>50K' and count_class2 < max_datapoints:\n",
    "            X.append(data)\n",
    "            count_class2 += 1\n",
    "\n",
    "# Convert to numpy array\n",
    "X = np.array(X)\n",
    "print(X)\n",
    "\n",
    "# Convert string data to numerical data\n",
    "label_encoder = [] \n",
    "X_encoded = np.empty(X.shape)\n",
    "print(X.shape)\n",
    "print(X_encoded)\n",
    "print(X[0])\n",
    "for i,item in enumerate(X[0]):\n",
    "    if item.isdigit(): \n",
    "        print(\"item is \",item)\n",
    "        print(X[:,i])\n",
    "        X_encoded[:, i] = X[:, i]\n",
    "    else:\n",
    "        label_encoder.append(preprocessing.LabelEncoder())\n",
    "        X_encoded[:, i] = label_encoder[-1].fit_transform(X[:, i])\n",
    "\n",
    "X = X_encoded[:, :-1].astype(int)\n",
    "y = X_encoded[:, -1].astype(int)\n",
    "print(X)\n",
    "print(y)\n",
    "# Create SVM classifier\n",
    "classifier = OneVsOneClassifier(LinearSVC(random_state=0))\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(X, y)\n",
    "\n",
    "# Cross validation\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "classifier = OneVsOneClassifier(LinearSVC(random_state=0))\n",
    "classifier.fit(X_train, y_train)\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "\n",
    "# Compute the F1 score of the SVM classifier\n",
    "f1 = cross_validation.cross_val_score(classifier, X, y, scoring='f1_weighted', cv=3)\n",
    "print(\"F1 score: \" + str(round(100*f1.mean(), 2)) + \"%\")\n",
    "\n",
    "# Predict output for a test datapoint\n",
    "input_data = ['37', 'Private', '215646', 'HS-grad', '9', 'Never-married', 'Handlers-cleaners', 'Not-in-family', 'White', 'Male', '0', '0', '40', 'United-States']\n",
    "\n",
    "# Encode test datapoint\n",
    "input_data_encoded = [-1] * len(input_data)\n",
    "count = 0\n",
    "for i, item in enumerate(input_data):\n",
    "    if item.isdigit():\n",
    "        input_data_encoded[i] = int(input_data[i])\n",
    "    else:\n",
    "        print(\"input data \")\n",
    "        print(input_data[i])\n",
    "        print(label_encoder[count])\n",
    "        input_data_encoded[i] = int(label_encoder[count].transform(input_data[i]))\n",
    "        count += 1 \n",
    "\n",
    "input_data_encoded = np.array(input_data_encoded)\n",
    "\n",
    "# Run classifier on encoded datapoint and print output\n",
    "predicted_class = classifier.predict(input_data_encoded)\n",
    "print(label_encoder[-1].inverse_transform(predicted_class)[0])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
